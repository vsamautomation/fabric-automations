{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "overview-section",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Fabric Model Analysis & Optimization Toolkit\n",
        "\n",
        "## Overview\n",
        "This notebook provides comprehensive functions for analyzing semantic models to identify unused objects (measures, columns, and tables) that can be removed to optimize model performance and reduce complexity.\n",
        "\n",
        "## Key Features\n",
        "- **Unused Measures Detection**: Identifies measures not referenced in calculations or reports\n",
        "- **Unused Columns Detection**: Finds columns not used in calculations or visualizations\n",
        "- **Unused Tables Detection**: Locates tables with no references in the model\n",
        "- **Relationship Analysis**: Examines table relationships for optimization opportunities\n",
        "\n",
        "## Required Libraries\n",
        "- `SemPy` which is part of the `semantic-link` feature with Core Fabric semantic model operations\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "installation-section",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Installation & Dependencies\n",
        "\n",
        "Install the required semantic-link-labs package for extended Fabric analytics capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a326b4d-eec9-4f1c-8dd5-a182b3ff5202",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "# Install semantic-link-labs for extended Fabric analytics\n",
        "!pip install semantic-link-labs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "imports-section",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Library Imports & Configuration\n",
        "\n",
        "Import essential libraries for Fabric model analysis:\n",
        "- **`sempy.fabric`**: Primary interface for Fabric operations\n",
        "- **`sempy_labs.report`**: Report analysis and object extraction\n",
        "- **`pandas`**: Data manipulation framework\n",
        "- **`matplotlib.pyplot`**: Data visualization and charting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fde6587-a45b-4017-adbc-d10233eb7d91",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_telemetry: sempy.relationships\n",
            "log_telemetry: sempy.dependencies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'azure'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import core libraries for Fabric model analysis\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfabric\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy_labs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReportWrapper\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Configuration: Update these values for your specific workspace and dataset\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sempy\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _version\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_environment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     _get_artifact_type,\n\u001b[32m      4\u001b[39m     _get_environment,\n\u001b[32m      5\u001b[39m     _get_root_activity_id,\n\u001b[32m      6\u001b[39m     _get_fabric_run_id,\n\u001b[32m      7\u001b[39m     get_notebook_workspace_id,\n\u001b[32m      8\u001b[39m     get_artifact_id,\n\u001b[32m      9\u001b[39m     _on_fabric,\n\u001b[32m     10\u001b[39m     _on_aiskill\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_log\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _initialize_log\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_telemetry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_telemetry\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sempy\\fabric\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_telemetry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_telemetry\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_flat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     create_folder,\n\u001b[32m      5\u001b[39m     create_lakehouse,\n\u001b[32m      6\u001b[39m     create_tom_server,\n\u001b[32m      7\u001b[39m     create_trace_connection,\n\u001b[32m      8\u001b[39m     create_notebook,\n\u001b[32m      9\u001b[39m     create_workspace,\n\u001b[32m     10\u001b[39m     delete_folder,\n\u001b[32m     11\u001b[39m     delete_item,\n\u001b[32m     12\u001b[39m     evaluate_dax,\n\u001b[32m     13\u001b[39m     evaluate_measure,\n\u001b[32m     14\u001b[39m     execute_xmla,\n\u001b[32m     15\u001b[39m     execute_tmsl,\n\u001b[32m     16\u001b[39m     get_roles,\n\u001b[32m     17\u001b[39m     get_row_level_security_permissions,\n\u001b[32m     18\u001b[39m     get_refresh_execution_details,\n\u001b[32m     19\u001b[39m     get_tmsl,\n\u001b[32m     20\u001b[39m     list_items,\n\u001b[32m     21\u001b[39m     list_capacities,\n\u001b[32m     22\u001b[39m     list_datasets,\n\u001b[32m     23\u001b[39m     list_expressions,\n\u001b[32m     24\u001b[39m     list_folders,\n\u001b[32m     25\u001b[39m     list_measures,\n\u001b[32m     26\u001b[39m     list_refresh_requests,\n\u001b[32m     27\u001b[39m     list_relationship_violations,\n\u001b[32m     28\u001b[39m     list_reports,\n\u001b[32m     29\u001b[39m     list_tables,\n\u001b[32m     30\u001b[39m     list_translations,\n\u001b[32m     31\u001b[39m     list_workspaces,\n\u001b[32m     32\u001b[39m     move_folder,\n\u001b[32m     33\u001b[39m     plot_relationships,\n\u001b[32m     34\u001b[39m     read_table,\n\u001b[32m     35\u001b[39m     refresh_dataset,\n\u001b[32m     36\u001b[39m     refresh_tom_cache,\n\u001b[32m     37\u001b[39m     rename_folder,\n\u001b[32m     38\u001b[39m     resolve_workspace_id,\n\u001b[32m     39\u001b[39m     resolve_workspace_name,\n\u001b[32m     40\u001b[39m     resolve_workspace_name_and_id,\n\u001b[32m     41\u001b[39m     resolve_dataset_id,\n\u001b[32m     42\u001b[39m     resolve_dataset_name,\n\u001b[32m     43\u001b[39m     resolve_dataset_name_and_id,\n\u001b[32m     44\u001b[39m     resolve_folder_id,\n\u001b[32m     45\u001b[39m     resolve_folder_path,\n\u001b[32m     46\u001b[39m     resolve_item_id,\n\u001b[32m     47\u001b[39m     resolve_item_name,\n\u001b[32m     48\u001b[39m     run_notebook_job,\n\u001b[32m     49\u001b[39m     _trace_evaluate_dax\n\u001b[32m     50\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_flat_list_annotations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_annotations\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_flat_list_apps\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_apps\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sempy\\fabric\\_flat.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dataframe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fabric_dataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FabricDataFrame\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetXmlaClient, DatasetRestClient\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_connection_mode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_connection_mode, ConnectionMode\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pbi_rest_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _PBIRestAPI\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sempy\\fabric\\_client\\__init__.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dataset_xmla_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetXmlaClient\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dataset_rest_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetRestClient\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_pbix_sample\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msempy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfabric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_translations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m translate_semantic_model\n\u001b[32m      7\u001b[39m __all__ = [\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWorkspaceClient\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDatasetRestClient\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtranslate_semantic_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sempy\\fabric\\_client\\_tools.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcredentials\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AccessToken\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstorage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlobServiceClient\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Union\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'azure'"
          ]
        }
      ],
      "source": [
        "# Import core libraries for Fabric model analysis\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sempy.fabric as fabric\n",
        "from sempy_labs.report import ReportWrapper\n",
        "\n",
        "# Configuration: Update these values for your specific workspace and dataset.\n",
        "WORKSPACE = \"Test Workspace\"\n",
        "DATASET = \"New Waziri Dashboard Report\"\n",
        "REPORT = \"New Waziri Dashboard Report\"  # Optional: Specify if report name is different from dataset name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "data-preparation-section",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Data Preparation Functions\n",
        "\n",
        "## Step 1: Get Model Dependencies & Report Objects\n",
        "\n",
        "### Libraries Used:\n",
        "- `fabric.get_model_calc_dependencies()`: Retrieves calculation dependencies\n",
        "- `ReportWrapper().list_semantic_model_objects()`: Gets objects used in reports\n",
        "\n",
        "These functions establish the foundation for analysis by gathering:\n",
        "1. **Dependencies DataFrame**: Shows which objects reference other objects\n",
        "2. **Report Objects DataFrame**: Lists objects actually used in report visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c14872c5-e87c-4369-8e05-40dd849ad3ce",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "def find_model_dependencies():\n",
        "    \"\"\"\n",
        "    Retrieves calculation dependencies from the semantic model.\n",
        "    \n",
        "    Uses fabric.get_model_calc_dependencies() to analyze which objects\n",
        "    reference other objects within the model (e.g., measures referencing columns).\n",
        "    \n",
        "    Returns:\n",
        "        pandas.DataFrame: Contains dependency relationships with columns:\n",
        "            - Object: The object that has dependencies\n",
        "            - Referenced Object: The object being referenced\n",
        "            - Referenced Object Type: Type (Measure, Column, Table, etc.)\n",
        "            - Referenced Table: Table containing the referenced object\n",
        "    \"\"\"\n",
        "    dependencies = fabric.get_model_calc_dependencies(\n",
        "        dataset=DATASET,\n",
        "        workspace=WORKSPACE\n",
        "    )\n",
        "\n",
        "    with dependencies as calc_deps:\n",
        "        df = getattr(calc_deps, \"dependencies_df\", None)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def find_report_objects():\n",
        "    \"\"\"\n",
        "    Identifies objects used in report visualizations.\n",
        "    \n",
        "    Uses ReportWrapper to scan report pages and extract semantic model\n",
        "    objects (measures, columns, tables) that are actively used in visuals.\n",
        "    \n",
        "    Returns:\n",
        "        pandas.DataFrame: Contains report usage data with columns:\n",
        "            - Object Type: Type of object (Measure, Column, Table)\n",
        "            - Object Name: Name of the object\n",
        "            - Table Name: Parent table name\n",
        "            - Report Page: Page where object is used\n",
        "            - Visual Type: Type of visual using the object\n",
        "    \"\"\"\n",
        "    rpt = ReportWrapper(\n",
        "        report=DATASET,\n",
        "        workspace=WORKSPACE\n",
        "    )\n",
        "\n",
        "    report_objects = rpt.list_semantic_model_objects()\n",
        "\n",
        "    return report_objects\n",
        "\n",
        "\n",
        "# Execute data preparation functions\n",
        "print(\"📊 Retrieving model dependencies...\")\n",
        "dependencies_df = find_model_dependencies()\n",
        "\n",
        "print(\"📈 Analyzing report object usage...\")\n",
        "report_objects = find_report_objects()\n",
        "\n",
        "print(f\"✅ Found {len(dependencies_df)} dependency relationships\")\n",
        "print(f\"✅ Found {len(report_objects)} objects used in reports\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb7f5a7e-870b-47fc-9dcf-981d9692a969",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 🎯 Unused Measures Analysis\n",
        "\n",
        "## How To Identify Unused Measures\n",
        "\n",
        "### Process Overview:\n",
        "1. **GET ALL MEASURES** - Extract complete measure inventory from model\n",
        "2. **GET REFERENCED MEASURES** - Find measures referenced by other calculations\n",
        "3. **GET MEASURES USED IN REPORT VISUALS** - Identify measures actively used in visualizations\n",
        "\n",
        "### Libraries Used:\n",
        "- `fabric.list_measures()`: Retrieves all measures from the semantic model\n",
        "- Dependencies DataFrame: Filters for measures referenced in calculations\n",
        "- Report Objects DataFrame: Filters for measures used in visualizations\n",
        "\n",
        "### Analysis Logic:\n",
        "```\n",
        "UNUSED MEASURES = ALL MEASURES - (REFERENCED MEASURES ∪ REPORT MEASURES)\n",
        "```\n",
        "\n",
        "**A measure is considered unused if:**\n",
        "- ❌ Not used in any report visualizations\n",
        "- ❌ Not referenced by other calculated columns or measures\n",
        "- ❌ Not used in calculated tables or other DAX expressions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1fb3bf9-bb8c-4e97-9051-4c1174f3d281",
      "metadata": {
        "collapsed": false,
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "def find_unused_measures(deps_df, report_objects):\n",
        "    \"\"\"\n",
        "    Identifies measures that are not used in reports or referenced by other objects.\n",
        "    \n",
        "    This function performs set operations to find measures that exist in the model\n",
        "    but are neither used in report visualizations nor referenced by other\n",
        "    calculated columns, measures, or DAX expressions.\n",
        "    \n",
        "    Args:\n",
        "        deps_df (pandas.DataFrame): Dependencies dataframe from find_model_dependencies()\n",
        "        report_objects (pandas.DataFrame): Report objects dataframe from find_report_objects()\n",
        "    \n",
        "    Returns:\n",
        "        set: Set of unused measure names that can potentially be removed\n",
        "    \n",
        "    Process:\n",
        "        1. Retrieves all measures using fabric.list_measures()\n",
        "        2. Finds measures referenced in dependencies (Referenced Object Type = 'Measure')\n",
        "        3. Finds measures used in report visuals (Object Type = 'Measure')\n",
        "        4. Returns measures not in either referenced or report sets\n",
        "    \"\"\"\n",
        "    \n",
        "    # GET ALL MEASURES - Complete inventory from semantic model\n",
        "    print(\"  📋 Retrieving all measures from semantic model...\")\n",
        "    measures_df = fabric.list_measures(\n",
        "        dataset=DATASET, \n",
        "        workspace=WORKSPACE\n",
        "    )\n",
        "\n",
        "    all_measures = set(measures_df['Measure Name'].unique())\n",
        "    print(f\"     └─ Found {len(all_measures)} total measures\")\n",
        "\n",
        "    # GET REFERENCED MEASURES - Used in other calculations\n",
        "    print(\"  🔗 Identifying measures referenced in calculations...\")\n",
        "    referenced_measures = set(\n",
        "        deps_df[deps_df['Referenced Object Type'] == 'Measure']['Referenced Object'].unique()\n",
        "    )\n",
        "    print(f\"     └─ Found {len(referenced_measures)} referenced measures\")\n",
        "\n",
        "    # GET MEASURES IN REPORT VISUALS - Actively used in reports\n",
        "    print(\"  📊 Finding measures used in report visualizations...\")\n",
        "    report_measures = set(report_objects[report_objects['Object Type']==\"Measure\"]['Object Name'].unique())\n",
        "    print(f\"     └─ Found {len(report_measures)} measures in reports\")\n",
        "\n",
        "    # CALCULATE USED MEASURES - Union of referenced and report measures\n",
        "    used_measures = report_measures.union(referenced_measures)\n",
        "    print(f\"  ✓ Total used measures: {len(used_measures)}\")\n",
        "\n",
        "    # RETURN UNUSED MEASURES - Set difference operation\n",
        "    unused_measures = all_measures.difference(used_measures)\n",
        "    print(f\"  🎯 Identified {len(unused_measures)} unused measures\")\n",
        "    \n",
        "    # Return both unused measures and metrics for visualization\n",
        "    return unused_measures, {\n",
        "        'total_measures': len(all_measures),\n",
        "        'unused_measures': len(unused_measures),\n",
        "        'used_measures': len(used_measures),\n",
        "        'utilization_rate': (len(used_measures) / len(all_measures)) * 100 if len(all_measures) > 0 else 0\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05155d42-b788-4aa1-a002-0cd9e97fe7cc",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "# Execute unused measures analysis\n",
        "print(\"🔍 EXECUTING UNUSED MEASURES ANALYSIS...\")\n",
        "print(\"=\" * 50)\n",
        "unused_measures, measures_metrics = find_unused_measures(deps_df=dependencies_df, report_objects=report_objects)\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Display results with enhanced formatting\n",
        "if unused_measures:\n",
        "    print(f\"🚨 RESULTS: {len(unused_measures)} UNUSED MEASURES FOUND\")\n",
        "    print(\"\\nThese measures can potentially be removed to optimize the model:\")\n",
        "    for i, measure in enumerate(sorted(unused_measures), 1):\n",
        "        print(f\"  {i:2d}. {measure}\")\n",
        "        \n",
        "    print(f\"\\n💾 Potential storage savings: ~{len(unused_measures)} objects\")\n",
        "    print(\"⚡ Performance impact: Faster model processing and reduced memory usage\")\n",
        "else:\n",
        "    print(\"✅ EXCELLENT! No unused measures found. Model is optimized.\")\n",
        "\n",
        "print(\"\\n📊 Summary Statistics:\")\n",
        "print(f\"   Total Measures: {measures_metrics['total_measures']}\")\n",
        "print(f\"   Unused Measures: {measures_metrics['unused_measures']}\")\n",
        "print(f\"   Used Measures: {measures_metrics['used_measures']}\")\n",
        "print(f\"   Utilization Rate: {measures_metrics['utilization_rate']:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "measures-visualization-cell",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "# 📈 ENHANCED VISUALIZATION: Measures & Columns Analysis\n",
        "print(\"\\n📈 GENERATING DUAL UTILIZATION CHARTS...\")\n",
        "\n",
        "# Get columns data for dual visualization\n",
        "total_columns = len(fabric.list_columns(dataset=DATASET, workspace=WORKSPACE))\n",
        "unused_columns_for_viz = get_unused_columns(dependencies_df, report_objects)\n",
        "used_columns = total_columns - len(unused_columns_for_viz)\n",
        "columns_utilization = (used_columns / total_columns * 100) if total_columns > 0 else 0\n",
        "\n",
        "# Create side-by-side charts\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# MEASURES CHART (Left)\n",
        "measures_labels = ['Used', 'Unused']\n",
        "measures_values = [measures_metrics['used_measures'], measures_metrics['unused_measures']]\n",
        "measures_colors = ['#28a745', '#dc3545']  # Green for used, red for unused\n",
        "\n",
        "bars1 = ax1.bar(measures_labels, measures_values, color=measures_colors, alpha=0.8, \n",
        "                 edgecolor='black', linewidth=1)\n",
        "\n",
        "# Add value labels on measures bars\n",
        "for i, bar in enumerate(bars1):\n",
        "    height = bar.get_height()\n",
        "    percentage = (measures_values[i] / measures_metrics['total_measures']) * 100\n",
        "    ax1.annotate(f'{int(height)}\\n({percentage:.1f}%)',\n",
        "                 xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                 xytext=(0, 5),\n",
        "                 textcoords=\"offset points\",\n",
        "                 ha='center', va='bottom', \n",
        "                 fontsize=12, fontweight='bold')\n",
        "\n",
        "# Customize measures chart\n",
        "ax1.set_ylabel('Number of Measures', fontsize=13, fontweight='bold')\n",
        "ax1.set_title(f'🎯 Measures Analysis\\nTotal: {measures_metrics[\"total_measures\"]} | Utilization: {measures_metrics[\"utilization_rate\"]:.1f}%',\n",
        "              fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.set_ylim(0, max(measures_values) * 1.3 if measures_values else 1)\n",
        "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax1.set_axisbelow(True)\n",
        "\n",
        "# COLUMNS CHART (Right)\n",
        "columns_labels = ['Used', 'Unused']\n",
        "columns_values = [used_columns, len(unused_columns_for_viz)]\n",
        "columns_colors = ['#17a2b8', '#fd7e14']  # Blue for used, orange for unused\n",
        "\n",
        "bars2 = ax2.bar(columns_labels, columns_values, color=columns_colors, alpha=0.8, \n",
        "                 edgecolor='black', linewidth=1)\n",
        "\n",
        "# Add value labels on columns bars\n",
        "for i, bar in enumerate(bars2):\n",
        "    height = bar.get_height()\n",
        "    percentage = (columns_values[i] / total_columns) * 100 if total_columns > 0 else 0\n",
        "    ax2.annotate(f'{int(height)}\\n({percentage:.1f}%)',\n",
        "                 xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                 xytext=(0, 5),\n",
        "                 textcoords=\"offset points\",\n",
        "                 ha='center', va='bottom', \n",
        "                 fontsize=12, fontweight='bold')\n",
        "\n",
        "# Customize columns chart\n",
        "ax2.set_ylabel('Number of Columns', fontsize=13, fontweight='bold')\n",
        "ax2.set_title(f'📊 Columns Analysis\\nTotal: {total_columns} | Utilization: {columns_utilization:.1f}%',\n",
        "              fontsize=14, fontweight='bold', pad=15)\n",
        "ax2.set_ylim(0, max(columns_values) * 1.3 if columns_values else 1)\n",
        "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax2.set_axisbelow(True)\n",
        "\n",
        "# Overall chart formatting\n",
        "fig.suptitle(f'🚀 {DATASET} - Model Optimization Analysis', \n",
        "             fontsize=16, fontweight='bold', y=0.95)\n",
        "\n",
        "# Style both charts\n",
        "for ax in [ax1, ax2]:\n",
        "    ax.tick_params(axis='x', labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.85)  # Make room for main title\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Dual charts generated successfully!\")\n",
        "print(f\"📊 Summary: {measures_metrics['used_measures']}/{measures_metrics['total_measures']} measures used, {used_columns}/{total_columns} columns used\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7393ac-2296-4595-99f7-74cb5b007c1d",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 📊 Unused Columns Analysis\n",
        "\n",
        "## How To Identify Unused Columns\n",
        "\n",
        "### Process Overview:\n",
        "1. **GET ALL COLUMNS** - Extract complete column inventory from all tables\n",
        "2. **GET REFERENCED COLUMNS** - Find columns referenced in calculations and measures\n",
        "3. **GET COLUMNS USED IN REPORTS** - Identify columns actively used in visualizations\n",
        "\n",
        "### Libraries Used:\n",
        "- `fabric.list_columns()`: Retrieves all columns from the semantic model\n",
        "- Dependencies DataFrame: Filters for Column and Calc Column object types\n",
        "- Report Objects DataFrame: Filters for columns used in visualizations\n",
        "\n",
        "### Analysis Logic:\n",
        "```\n",
        "UNUSED COLUMNS = ALL COLUMNS - (REFERENCED COLUMNS ∪ REPORT COLUMNS)\n",
        "```\n",
        "\n",
        "**A column is considered unused if:**\n",
        "- ❌ Not used in any report visualizations (filters, axes, legends, values)\n",
        "- ❌ Not referenced by calculated columns or measures\n",
        "- ❌ Not used in relationships (foreign/primary keys)\n",
        "- ❌ Not used in row-level security expressions\n",
        "\n",
        "**⚠️ Important Considerations:**\n",
        "- Some columns may be used in external reports or applications\n",
        "- Key columns for relationships should be retained even if not directly used\n",
        "- Consider business requirements before removing columns\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd45248e-af7f-4cc8-9f04-b0b2d2c4b511",
      "metadata": {
        "collapsed": false,
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "def get_unused_columns(deps_df, report_objects):\n",
        "    \"\"\"\n",
        "    Identifies columns that are not used in reports or referenced by other objects.\n",
        "    \n",
        "    This function analyzes both regular columns and calculated columns to determine\n",
        "    which ones are not being utilized in the semantic model or reports.\n",
        "    \n",
        "    Args:\n",
        "        deps_df (pandas.DataFrame): Dependencies dataframe from find_model_dependencies()\n",
        "        report_objects (pandas.DataFrame): Report objects dataframe from find_report_objects()\n",
        "    \n",
        "    Returns:\n",
        "        set: Set of unused column names that can potentially be removed\n",
        "    \n",
        "    Process:\n",
        "        1. Retrieves all columns using fabric.list_columns()\n",
        "        2. Finds columns referenced in dependencies (both Column and Calc Column types)\n",
        "        3. Finds columns used in report visuals\n",
        "        4. Returns columns not in either referenced or report sets\n",
        "    \"\"\"\n",
        "    \n",
        "    # GET ALL COLUMNS - Complete inventory from all tables\n",
        "    print(\"  📋 Retrieving all columns from semantic model...\")\n",
        "    columns_df = fabric.list_columns(\n",
        "        dataset=DATASET, \n",
        "        workspace=WORKSPACE\n",
        "        )\n",
        "    all_columns = set(columns_df['Column Name'].unique())\n",
        "    print(f\"     └─ Found {len(all_columns)} total columns across all tables\")\n",
        "\n",
        "    # GET REFERENCED COLUMNS - Used in calculations\n",
        "    print(\"  🔗 Identifying columns referenced in calculations...\")\n",
        "    col_object_types = [\"Column\", \"Calc Column\"]  # Include both regular and calculated columns\n",
        "    referenced_columns = set(\n",
        "        deps_df[deps_df['Referenced Object Type'].isin(col_object_types)]['Referenced Object'].unique()\n",
        "    )\n",
        "    print(f\"     └─ Found {len(referenced_columns)} referenced columns\")\n",
        "\n",
        "    # GET COLUMNS USED DIRECTLY IN REPORTS - Active in visualizations\n",
        "    print(\"  📊 Finding columns used in report visualizations...\")\n",
        "    report_columns = set(report_objects[report_objects['Object Type'] == \"Column\"]['Object Name'].unique())\n",
        "    print(f\"     └─ Found {len(report_columns)} columns in reports\")\n",
        "\n",
        "    # CALCULATE USED COLUMNS - Union of referenced and report columns\n",
        "    used_columns = report_columns.union(referenced_columns)\n",
        "    print(f\"  ✓ Total used columns: {len(used_columns)}\")\n",
        "\n",
        "    # RETURN UNUSED COLUMNS - Set difference operation\n",
        "    unused_columns = all_columns.difference(used_columns)\n",
        "    print(f\"  🎯 Identified {len(unused_columns)} unused columns\")\n",
        "    \n",
        "    return unused_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e38e3c9-b574-4458-aa9b-e1390f60fbf4",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "# Execute unused columns analysis\n",
        "print(\"🔍 EXECUTING UNUSED COLUMNS ANALYSIS...\")\n",
        "print(\"=\" * 50)\n",
        "unused_columns = get_unused_columns(deps_df=dependencies_df, report_objects=report_objects)\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Display results with enhanced formatting\n",
        "if unused_columns:\n",
        "    print(f\"🚨 RESULTS: {len(unused_columns)} UNUSED COLUMNS FOUND\")\n",
        "    print(\"\\nThese columns can potentially be removed to optimize the model:\")\n",
        "    \n",
        "    # Group columns by likely category for better organization\n",
        "    date_cols = [col for col in unused_columns if any(x in col.lower() for x in ['date', 'week', 'month', 'quarter', 'year', 'day'])]\n",
        "    financial_cols = [col for col in unused_columns if any(x in col.lower() for x in ['cost', 'sales', 'profit', 'amount', 'balance', 'vat'])]\n",
        "    other_cols = [col for col in unused_columns if col not in date_cols + financial_cols]\n",
        "    \n",
        "    if date_cols:\n",
        "        print(f\"\\n  📅 Date/Time Columns ({len(date_cols)}):\")\n",
        "        for col in sorted(date_cols)[:10]:  # Show first 10\n",
        "            print(f\"     • {col}\")\n",
        "        if len(date_cols) > 10: print(f\"     ... and {len(date_cols)-10} more\")\n",
        "    \n",
        "    if financial_cols:\n",
        "        print(f\"\\n  💰 Financial Columns ({len(financial_cols)}):\")\n",
        "        for col in sorted(financial_cols):\n",
        "            print(f\"     • {col}\")\n",
        "    \n",
        "    if other_cols:\n",
        "        print(f\"\\n  🔧 Other Columns ({len(other_cols)}):\")\n",
        "        for col in sorted(other_cols)[:15]:  # Show first 15\n",
        "            print(f\"     • {col}\")\n",
        "        if len(other_cols) > 15: print(f\"     ... and {len(other_cols)-15} more\")\n",
        "        \n",
        "    print(f\"\\n💾 Potential storage savings: ~{len(unused_columns)} columns\")\n",
        "    print(\"⚡ Performance impact: Faster queries and reduced memory usage\")\n",
        "    print(\"⚠️  Note: Review relationship keys before removing columns\")\n",
        "else:\n",
        "    print(\"✅ EXCELLENT! No unused columns found. Model is optimized.\")\n",
        "\n",
        "print(\"\\n📊 Summary Statistics:\")\n",
        "total_columns = len(fabric.list_columns(dataset=DATASET, workspace=WORKSPACE))\n",
        "print(f\"   Total Columns: {total_columns}\")\n",
        "print(f\"   Unused Columns: {len(unused_columns)}\")\n",
        "print(f\"   Utilization Rate: {((total_columns - len(unused_columns)) / total_columns * 100):.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1626453a-c21e-4e6f-8b4a-470382bddc30",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 🗃️ Unused Tables Analysis\n",
        "\n",
        "## How To Identify Unused Tables\n",
        "\n",
        "### Process Overview:\n",
        "1. **GET ALL TABLES** - Extract complete table inventory from the semantic model\n",
        "2. **GET REFERENCED TABLES** - Find tables referenced in calculations and measures\n",
        "3. **GET TABLES USED IN REPORTS** - Identify tables with objects used in visualizations\n",
        "\n",
        "### Libraries Used:\n",
        "- `fabric.list_tables()`: Retrieves all tables from the semantic model\n",
        "- Dependencies DataFrame: Extracts Referenced Table column values\n",
        "- Report Objects DataFrame: Extracts Table Name column values\n",
        "\n",
        "### Analysis Logic:\n",
        "```\n",
        "UNUSED TABLES = ALL TABLES - (REFERENCED TABLES ∪ REPORT TABLES)\n",
        "```\n",
        "\n",
        "**A table is considered unused if:**\n",
        "- ❌ No columns from the table are used in report visualizations\n",
        "- ❌ No measures reference columns from this table\n",
        "- ❌ No calculated columns reference this table\n",
        "- ❌ No relationships connect this table to active parts of the model\n",
        "\n",
        "**⚠️ Critical Considerations:**\n",
        "- **Review relationships carefully** - Key tables may be needed for joins\n",
        "- **Check for external dependencies** - May be used by other reports/apps\n",
        "- **Verify business requirements** - Some tables may be needed for future use\n",
        "- **Consider bridge tables** - May be essential for many-to-many relationships\n",
        "\n",
        "**💡 Safe Removal Criteria:**\n",
        "- Table has no active relationships\n",
        "- No external reports depend on this table\n",
        "- Business stakeholders confirm it's no longer needed\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3482f37d-02a7-4f17-ae2a-552c9de50971",
      "metadata": {
        "collapsed": false,
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "def get_unused_tables(deps_df, report_objects):\n",
        "    \"\"\"\n",
        "    Identifies tables that are not used in reports or referenced by other objects.\n",
        "    \n",
        "    This function analyzes table usage across the entire semantic model to identify\n",
        "    tables that have no active references or report usage.\n",
        "    \n",
        "    Args:\n",
        "        deps_df (pandas.DataFrame): Dependencies dataframe from find_model_dependencies()\n",
        "        report_objects (pandas.DataFrame): Report objects dataframe from find_report_objects()\n",
        "    \n",
        "    Returns:\n",
        "        set: Set of unused table names that can potentially be removed\n",
        "    \n",
        "    Process:\n",
        "        1. Retrieves all tables using fabric.list_tables()\n",
        "        2. Finds tables referenced in dependencies (Referenced Table column)\n",
        "        3. Finds tables with objects used in report visuals (Table Name column)\n",
        "        4. Returns tables not in either referenced or report sets\n",
        "    \n",
        "    Warning:\n",
        "        Exercise extreme caution when removing tables. Verify relationships\n",
        "        and external dependencies before deletion.\n",
        "    \"\"\"\n",
        "    \n",
        "    # GET ALL TABLES - Complete inventory from semantic model\n",
        "    print(\"  📋 Retrieving all tables from semantic model...\")\n",
        "    tables_df = fabric.list_tables(\n",
        "        dataset=DATASET, \n",
        "        workspace=WORKSPACE\n",
        "    )\n",
        "    all_tables = set(tables_df['Name'].unique())\n",
        "    print(f\"     └─ Found {len(all_tables)} total tables\")\n",
        "\n",
        "    # GET REFERENCED TABLES - Used in calculations\n",
        "    print(\"  🔗 Identifying tables referenced in calculations...\")\n",
        "    referenced_tables = set(\n",
        "        deps_df['Referenced Table'].dropna().unique()\n",
        "    )\n",
        "    print(f\"     └─ Found {len(referenced_tables)} referenced tables\")\n",
        "\n",
        "    # GET TABLES USED DIRECTLY IN REPORTS - Have objects in visualizations\n",
        "    print(\"  📊 Finding tables with objects used in reports...\")\n",
        "    report_tables = set(\n",
        "        report_objects['Table Name'].unique()\n",
        "    )\n",
        "    print(f\"     └─ Found {len(report_tables)} tables used in reports\")\n",
        "\n",
        "    # CALCULATE USED TABLES - Union of referenced and report tables\n",
        "    used_tables = referenced_tables.union(report_tables)\n",
        "    print(f\"  ✓ Total used tables: {len(used_tables)}\")\n",
        "\n",
        "    # RETURN UNUSED TABLES - Set difference operation\n",
        "    unused_tables = all_tables.difference(used_tables)\n",
        "    print(f\"  🎯 Identified {len(unused_tables)} unused tables\")\n",
        "    \n",
        "    return unused_tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1957e47-c666-4f08-a00e-6654d5498333",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "# Execute unused tables analysis\n",
        "print(\"🔍 EXECUTING UNUSED TABLES ANALYSIS...\")\n",
        "print(\"=\" * 50)\n",
        "unused_tables = get_unused_tables(deps_df=dependencies_df, report_objects=report_objects)\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Display results with enhanced formatting and warnings\n",
        "if unused_tables:\n",
        "    print(f\"🚨 RESULTS: {len(unused_tables)} UNUSED TABLES FOUND\")\n",
        "    print(\"\\n⚠️  CRITICAL WARNING: Review these tables carefully before removal!\")\n",
        "    print(\"\\nPotentially unused tables:\")\n",
        "    for i, table in enumerate(sorted(unused_tables), 1):\n",
        "        print(f\"  {i:2d}. {table}\")\n",
        "        \n",
        "    print(\"\\n🔍 RECOMMENDED VERIFICATION STEPS:\")\n",
        "    print(\"   1. Check if tables are used in relationships (even inactive ones)\")\n",
        "    print(\"   2. Verify no external reports or applications use these tables\")\n",
        "    print(\"   3. Confirm with business stakeholders before removal\")\n",
        "    print(\"   4. Consider if tables are needed for future development\")\n",
        "    print(\"   5. Review table relationships and cardinality\")\n",
        "        \n",
        "    print(f\"\\n💾 Potential storage savings: ~{len(unused_tables)} tables\")\n",
        "    print(\"⚡ Performance impact: Reduced model complexity and faster refresh\")\n",
        "else:\n",
        "    print(\"✅ EXCELLENT! No unused tables found. Model structure is optimized.\")\n",
        "\n",
        "print(\"\\n📊 Summary Statistics:\")\n",
        "total_tables = len(fabric.list_tables(dataset=DATASET, workspace=WORKSPACE))\n",
        "print(f\"   Total Tables: {total_tables}\")\n",
        "print(f\"   Unused Tables: {len(unused_tables)}\")\n",
        "print(f\"   Utilization Rate: {((total_tables - len(unused_tables)) / total_tables * 100):.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "relationship-analysis-header",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 🔗 Relationship Analysis\n",
        "\n",
        "## Model Relationships Overview\n",
        "\n",
        "Understanding table relationships is crucial for validating unused table analysis.\n",
        "Tables that appear \"unused\" might still be essential for maintaining proper\n",
        "relationships and data integrity.\n",
        "\n",
        "### Libraries Used:\n",
        "- `fabric.list_relationships()`: Retrieves all relationships with extended properties\n",
        "\n",
        "### Key Relationship Properties:\n",
        "- **Multiplicity**: Defines the relationship type (1:1, 1:*, *:*)\n",
        "- **Active**: Whether the relationship is active for filtering\n",
        "- **Cross Filtering Behavior**: Direction of filter propagation\n",
        "- **Cardinality**: Number of unique values in relationship columns\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed391fb0-e96e-4883-8ff7-9c8253fc6954",
      "metadata": {
        "collapsed": false,
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "# Analyze model relationships to understand table dependencies\n",
        "print(\"🔗 ANALYZING MODEL RELATIONSHIPS...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# GET ALL RELATIONSHIPS with extended properties\n",
        "relationships_df = fabric.list_relationships(\n",
        "    workspace = WORKSPACE,\n",
        "    dataset = DATASET,\n",
        "    extended=True  # Include cardinality and other extended properties\n",
        ")\n",
        "\n",
        "print(f\"📊 Found {len(relationships_df)} relationships in the model\")\n",
        "\n",
        "# Analyze relationship patterns\n",
        "active_relationships = relationships_df[relationships_df['Active'] == True]\n",
        "inactive_relationships = relationships_df[relationships_df['Active'] == False]\n",
        "\n",
        "print(f\"✅ Active relationships: {len(active_relationships)}\")\n",
        "print(f\"❌ Inactive relationships: {len(inactive_relationships)}\")\n",
        "\n",
        "# Get unique tables involved in relationships\n",
        "tables_in_relationships = set(relationships_df['From Table'].unique()) | set(relationships_df['To Table'].unique())\n",
        "print(f\"🗃️  Tables involved in relationships: {len(tables_in_relationships)}\")\n",
        "\n",
        "# Cross-reference with unused tables\n",
        "if unused_tables:\n",
        "    unused_tables_with_relationships = unused_tables.intersection(tables_in_relationships)\n",
        "    if unused_tables_with_relationships:\n",
        "        print(f\"\\n⚠️  WARNING: {len(unused_tables_with_relationships)} unused tables have relationships!\")\n",
        "        print(\"   These tables should be reviewed carefully:\")\n",
        "        for table in sorted(unused_tables_with_relationships):\n",
        "            print(f\"     • {table}\")\n",
        "    else:\n",
        "        print(\"\\n✅ No unused tables have active relationships - safer to remove\")\n",
        "\n",
        "print(\"\\n📋 Relationship Summary Table:\")\n",
        "display(relationships_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "main-function-header",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 🚀 Complete Model Analysis Execution\n",
        "\n",
        "## Main Analysis Function\n",
        "\n",
        "The `run_complete_analysis()` function executes all analysis steps in sequence:\n",
        "1. **Data Preparation** - Gathers dependencies and report objects\n",
        "2. **Measures Analysis** - Identifies unused measures with visualization\n",
        "3. **Columns Analysis** - Finds unused columns with categorization\n",
        "4. **Tables Analysis** - Locates unused tables with warnings\n",
        "5. **Relationships Analysis** - Reviews model relationships\n",
        "6. **Dual Visualization** - Shows measures AND columns side-by-side\n",
        "7. **Summary Report** - Provides optimization recommendations\n",
        "\n",
        "**Benefits of using the main function:**\n",
        "- All results displayed in a single output\n",
        "- Consistent execution flow\n",
        "- Easy to track progress\n",
        "- Professional reporting format\n",
        "- Side-by-side visualization of measures and columns\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "main-analysis-function",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "def run_complete_analysis():\n",
        "    \"\"\"\n",
        "    Execute complete Fabric semantic model analysis.\n",
        "    \n",
        "    This main function orchestrates all analysis steps:\n",
        "    1. Data preparation (dependencies and report objects)\n",
        "    2. Unused measures analysis with visualization\n",
        "    3. Unused columns analysis with categorization\n",
        "    4. Unused tables analysis with warnings\n",
        "    5. Relationships analysis for validation\n",
        "    6. Dual visualization (measures + columns charts)\n",
        "    7. Summary report with recommendations\n",
        "    \n",
        "    Returns:\n",
        "        dict: Complete analysis results with all metrics and findings\n",
        "    \"\"\"\n",
        "    \n",
        "    print('🚀' + '=' * 70)\n",
        "    print(\"🎯 FABRIC SEMANTIC MODEL OPTIMIZATION ANALYSIS\")\n",
        "    print(\"=\" * 72)\n",
        "    print(f\"📊 Workspace: {WORKSPACE}\")\n",
        "    print(f\"📈 Dataset: {DATASET}\")\n",
        "    print(\"=\" * 72)\n",
        "\n",
        "\n",
        "    \n",
        "    # STEP 1: DATA PREPARATION\n",
        "    print(\"📋 STEP 1: DATA PREPARATION\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"📊 Retrieving model dependencies...\")\n",
        "    dependencies_df = find_model_dependencies()\n",
        "    \n",
        "    print(\"📈 Analyzing report object usage...\")\n",
        "    report_objects = find_report_objects()\n",
        "    \n",
        "    print(f\"✅ Found {len(dependencies_df)} dependency relationships\")\n",
        "    print(f\"✅ Found {len(report_objects)} objects used in reports\\n\")\n",
        "    \n",
        "    # STEP 2: MEASURES ANALYSIS\n",
        "    print(\"🎯 STEP 2: UNUSED MEASURES ANALYSIS\")\n",
        "    print(\"-\" * 40)\n",
        "    unused_measures, measures_metrics = find_unused_measures(dependencies_df, report_objects)\n",
        "    \n",
        "    # Display measures results\n",
        "    if unused_measures:\n",
        "        print(f\"🚨 RESULTS: {len(unused_measures)} UNUSED MEASURES FOUND\")\n",
        "        print(\"\\nUnused measures that can be removed:\")\n",
        "        for i, measure in enumerate(sorted(unused_measures), 1):\n",
        "            print(f\"  {i:2d}. {measure}\")\n",
        "        print(f\"\\n💾 Storage savings: ~{len(unused_measures)} objects\")\n",
        "    else:\n",
        "        print(\"✅ EXCELLENT! No unused measures found.\")\n",
        "    \n",
        "    print(f\"📊 Measures Summary: {measures_metrics['used_measures']}/{measures_metrics['total_measures']} used ({measures_metrics['utilization_rate']:.1f}% utilization)\\n\")\n",
        "    \n",
        "    # STEP 3: COLUMNS ANALYSIS\n",
        "    print(\"📊 STEP 3: UNUSED COLUMNS ANALYSIS\")\n",
        "    print(\"-\" * 40)\n",
        "    unused_columns = get_unused_columns(dependencies_df, report_objects)\n",
        "    \n",
        "    # Categorize and display columns results\n",
        "    if unused_columns:\n",
        "        print(f\"🚨 RESULTS: {len(unused_columns)} UNUSED COLUMNS FOUND\")\n",
        "        \n",
        "        # Group columns by category\n",
        "        date_cols = [col for col in unused_columns if any(x in col.lower() for x in ['date', 'week', 'month', 'quarter', 'year', 'day'])]\n",
        "        financial_cols = [col for col in unused_columns if any(x in col.lower() for x in ['cost', 'sales', 'profit', 'amount', 'balance', 'vat'])]\n",
        "        other_cols = [col for col in unused_columns if col not in date_cols + financial_cols]\n",
        "        \n",
        "        if date_cols:\n",
        "            print(f\"\\n📅 Date/Time Columns ({len(date_cols)}):\")\n",
        "            for col in sorted(date_cols)[:5]: print(f\"   • {col}\")\n",
        "            if len(date_cols) > 5: print(f\"   ... and {len(date_cols)-5} more\")\n",
        "        \n",
        "        if financial_cols:\n",
        "            print(f\"\\n💰 Financial Columns ({len(financial_cols)}):\")\n",
        "            for col in sorted(financial_cols): print(f\"   • {col}\")\n",
        "        \n",
        "        if other_cols:\n",
        "            print(f\"\\n🔧 Other Columns ({len(other_cols)}):\")\n",
        "            for col in sorted(other_cols)[:5]: print(f\"   • {col}\")\n",
        "            if len(other_cols) > 5: print(f\"   ... and {len(other_cols)-5} more\")\n",
        "        \n",
        "        print(f\"💾 Storage savings: ~{len(unused_columns)} columns\")\n",
        "        print(\"⚠️  Note: Review relationship keys before removal\")\n",
        "    else:\n",
        "        print(\"✅ EXCELLENT! No unused columns found.\")\n",
        "    \n",
        "    total_columns = len(fabric.list_columns(dataset=DATASET, workspace=WORKSPACE))\n",
        "    columns_utilization = ((total_columns - len(unused_columns)) / total_columns * 100) if total_columns > 0 else 0\n",
        "    print(f\"📊 Columns Summary: {total_columns - len(unused_columns)}/{total_columns} used ({columns_utilization:.1f}% utilization)\\n\")\n",
        "    \n",
        "    # STEP 4: TABLES ANALYSIS\n",
        "    print(\"🗃️ STEP 4: UNUSED TABLES ANALYSIS\")\n",
        "    print(\"-\" * 40)\n",
        "    unused_tables = get_unused_tables(dependencies_df, report_objects)\n",
        "    \n",
        "    # Display tables results with warnings\n",
        "    if unused_tables:\n",
        "        print(f\"🚨 RESULTS: {len(unused_tables)} UNUSED TABLES FOUND\")\n",
        "        print(\"⚠️  CRITICAL WARNING: Review carefully before removal!\")\n",
        "        print(\"\\nPotentially unused tables:\")\n",
        "        for i, table in enumerate(sorted(unused_tables), 1):\n",
        "            print(f\"  {i:2d}. {table}\")\n",
        "        print(f\"\\n💾 Storage savings: ~{len(unused_tables)} tables\")\n",
        "    else:\n",
        "        print(\"✅ EXCELLENT! No unused tables found.\")\n",
        "    \n",
        "    total_tables = len(fabric.list_tables(dataset=DATASET, workspace=WORKSPACE))\n",
        "    tables_utilization = ((total_tables - len(unused_tables)) / total_tables * 100) if total_tables > 0 else 0\n",
        "    print(f\"📊 Tables Summary: {total_tables - len(unused_tables)}/{total_tables} used ({tables_utilization:.1f}% utilization)\\n\")\n",
        "    \n",
        "    # STEP 5: RELATIONSHIPS ANALYSIS\n",
        "    print(\"🔗 STEP 5: RELATIONSHIPS ANALYSIS\")\n",
        "    print(\"-\" * 40)\n",
        "    relationships_df = fabric.list_relationships(workspace=WORKSPACE, dataset=DATASET, extended=True)\n",
        "    active_relationships = relationships_df[relationships_df['Active'] == True]\n",
        "    inactive_relationships = relationships_df[relationships_df['Active'] == False]\n",
        "    \n",
        "    print(f\"📊 Found {len(relationships_df)} total relationships\")\n",
        "    print(f\"✅ Active relationships: {len(active_relationships)}\")\n",
        "    print(f\"❌ Inactive relationships: {len(inactive_relationships)}\")\n",
        "    \n",
        "    # Check unused tables with relationships\n",
        "    if unused_tables:\n",
        "        tables_in_relationships = set(relationships_df['From Table'].unique()) | set(relationships_df['To Table'].unique())\n",
        "        unused_tables_with_relationships = unused_tables.intersection(tables_in_relationships)\n",
        "        if unused_tables_with_relationships:\n",
        "            print(f\"⚠️  WARNING: {len(unused_tables_with_relationships)} unused tables have relationships!\")\n",
        "            for table in sorted(unused_tables_with_relationships):\n",
        "                print(f\"     • {table}\")\n",
        "        else:\n",
        "            print(\"✅ No unused tables have relationships - safer to remove\")\n",
        "    print()\n",
        "    \n",
        "    # STEP 6: ENHANCED DUAL VISUALIZATION\n",
        "    print(\"📈 STEP 6: GENERATING DUAL VISUALIZATIONS\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Create side-by-side visualizations for measures and columns\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    \n",
        "    # MEASURES CHART (Left)\n",
        "    measures_labels = ['Used', 'Unused']\n",
        "    measures_values = [measures_metrics['used_measures'], measures_metrics['unused_measures']]\n",
        "    measures_colors = ['#28a745', '#dc3545']  # Green for used, red for unused\n",
        "    \n",
        "    bars1 = ax1.bar(measures_labels, measures_values, color=measures_colors, alpha=0.8, \n",
        "                     edgecolor='black', linewidth=1)\n",
        "    \n",
        "    # Add value labels on measures bars\n",
        "    for i, bar in enumerate(bars1):\n",
        "        height = bar.get_height()\n",
        "        percentage = (measures_values[i] / measures_metrics['total_measures']) * 100\n",
        "        ax1.annotate(f'{int(height)}\\n({percentage:.1f}%)',\n",
        "                     xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                     xytext=(0, 5),\n",
        "                     textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom', \n",
        "                     fontsize=12, fontweight='bold')\n",
        "    \n",
        "    # Customize measures chart\n",
        "    ax1.set_ylabel('Number of Measures', fontsize=13, fontweight='bold')\n",
        "    ax1.set_title(f'🎯 Measures Analysis\\nTotal: {measures_metrics[\"total_measures\"]} | Utilization: {measures_metrics[\"utilization_rate\"]:.1f}%',\n",
        "                  fontsize=14, fontweight='bold', pad=15)\n",
        "    ax1.set_ylim(0, max(measures_values) * 1.3)\n",
        "    ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax1.set_axisbelow(True)\n",
        "    \n",
        "    # COLUMNS CHART (Right)\n",
        "    used_columns = total_columns - len(unused_columns)\n",
        "    columns_labels = ['Used', 'Unused']\n",
        "    columns_values = [used_columns, len(unused_columns)]\n",
        "    columns_colors = ['#17a2b8', '#fd7e14']  # Blue for used, orange for unused\n",
        "    \n",
        "    bars2 = ax2.bar(columns_labels, columns_values, color=columns_colors, alpha=0.8, \n",
        "                     edgecolor='black', linewidth=1)\n",
        "    \n",
        "    # Add value labels on columns bars\n",
        "    for i, bar in enumerate(bars2):\n",
        "        height = bar.get_height()\n",
        "        percentage = (columns_values[i] / total_columns) * 100 if total_columns > 0 else 0\n",
        "        ax2.annotate(f'{int(height)}\\n({percentage:.1f}%)',\n",
        "                     xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                     xytext=(0, 5),\n",
        "                     textcoords=\"offset points\",\n",
        "                     ha='center', va='bottom', \n",
        "                     fontsize=12, fontweight='bold')\n",
        "    \n",
        "    # Customize columns chart\n",
        "    ax2.set_ylabel('Number of Columns', fontsize=13, fontweight='bold')\n",
        "    ax2.set_title(f'📊 Columns Analysis\\nTotal: {total_columns} | Utilization: {columns_utilization:.1f}%',\n",
        "                  fontsize=14, fontweight='bold', pad=15)\n",
        "    ax2.set_ylim(0, max(columns_values) * 1.3 if columns_values else 1)\n",
        "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax2.set_axisbelow(True)\n",
        "    \n",
        "    # Overall chart formatting\n",
        "    fig.suptitle(f'🚀 {DATASET} - Model Optimization Analysis', \n",
        "                 fontsize=16, fontweight='bold', y=0.95)\n",
        "    \n",
        "    # Style both charts\n",
        "    for ax in [ax1, ax2]:\n",
        "        ax.tick_params(axis='x', labelsize=12)\n",
        "        ax.tick_params(axis='y', labelsize=11)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.85)  # Make room for main title\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"✅ Dual visualization generated successfully!\")\n",
        "    \n",
        "    # FINAL SUMMARY\n",
        "    print(\"\\n\" + \"=\" * 72)\n",
        "    print(\"🎯 ANALYSIS COMPLETE - OPTIMIZATION SUMMARY\")\n",
        "    print(\"=\" * 72)\n",
        "    print(f\"📊 Measures: {measures_metrics['unused_measures']}/{measures_metrics['total_measures']} unused ({100-measures_metrics['utilization_rate']:.1f}%)\")\n",
        "    print(f\"📊 Columns:  {len(unused_columns)}/{total_columns} unused ({100-columns_utilization:.1f}%)\")\n",
        "    print(f\"📊 Tables:   {len(unused_tables)}/{total_tables} unused ({100-tables_utilization:.1f}%)\")\n",
        "    print(f\"📊 Relationships: {len(active_relationships)} active, {len(inactive_relationships)} inactive\")\n",
        "    \n",
        "    total_unused_objects = len(unused_measures) + len(unused_columns) + len(unused_tables)\n",
        "    if total_unused_objects > 0:\n",
        "        print(f\"\\n💾 OPTIMIZATION POTENTIAL: {total_unused_objects} unused objects found\")\n",
        "        print(\"⚡ Expected benefits: Faster queries, reduced memory, simplified model\")\n",
        "        print(\"⚠️  Recommendation: Review and remove unused objects safely\")\n",
        "    else:\n",
        "        print(\"\\n✅ MODEL IS OPTIMIZED: No unused objects found!\")\n",
        "        print(\"🎉 Your semantic model is efficiently structured.\")\n",
        "    \n",
        "    print(\"=\" * 72)\n",
        "    print(\"🚀 Analysis completed successfully!\")\n",
        "    print(\"=\" * 72)\n",
        "    \n",
        "    # Return results for further processing if needed\n",
        "    return {\n",
        "        'unused_measures': unused_measures,\n",
        "        'unused_columns': unused_columns,\n",
        "        'unused_tables': unused_tables,\n",
        "        'measures_metrics': measures_metrics,\n",
        "        'columns_metrics': {'total': total_columns, 'unused': len(unused_columns), 'utilization': columns_utilization},\n",
        "        'tables_metrics': {'total': total_tables, 'unused': len(unused_tables), 'utilization': tables_utilization},\n",
        "        'relationships_df': relationships_df,\n",
        "        'dependencies_df': dependencies_df,\n",
        "        'report_objects': report_objects\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "execution-instructions",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 🎬 Execute Complete Analysis\n",
        "\n",
        "Run the cell below to execute the complete semantic model analysis.\n",
        "All results will be displayed in a single, organized output with dual visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "main-execution-cell",
      "metadata": {
        "microsoft": {
          "language": "python",
          "language_group": "synapse_pyspark"
        }
      },
      "outputs": [],
      "source": [
        "# 🚀 EXECUTE COMPLETE ANALYSIS WITH DUAL VISUALIZATION\n",
        "# Run this cell to perform comprehensive semantic model analysis\n",
        "# Features dual charts showing both measures and columns utilization\n",
        "\n",
        "analysis_results = run_complete_analysis()"
      ]
    }
  ],
  "metadata": {
    "dependencies": {},
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "microsoft": {
      "language": "python",
      "language_group": "synapse_pyspark",
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "spark_compute": {
      "compute_id": "/trident/default",
      "session_options": {
        "conf": {
          "spark.synapse.nbs.session.timeout": "1200000"
        }
      }
    },
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
